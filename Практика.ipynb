{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9QW4YcC8/vG10Uny6OYmN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PENROG21/PySpark/blob/main/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполнение практических заданий"
      ],
      "metadata": {
        "id": "ofdu49_my1Gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Самостоятельное задание  №1. Погода\n",
        "У вас есть данные о погоде за несколько лет, собранные из различных метеостанций. Ваша задача — проанализировать эти данные, чтобы выявить тренды и аномалии.\n",
        "\n",
        "Данные о погоде представлены в формате CSV и содержат следующие столбцы:\n",
        "\n",
        "`station_id`: ID метеостанции\n",
        "`date`: Дата наблюдения (в формате YYYY-MM-DD)\n",
        "`temperature`: Средняя температура в градусах Цельсия\n",
        "\n",
        "`precipitation`: Количество осадков в миллиметрах\n",
        "\n",
        "`wind_speed`: Средняя скорость ветра в метрах в секунду"
      ],
      "metadata": {
        "id": "-BbF07KjzDZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импорт"
      ],
      "metadata": {
        "id": "nF04K6BTy6T6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioU_ZUOa_Nk6",
        "outputId": "b00cf805-bbc7-409d-9d14-11af68bc02f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполните следующие пункты по порядку.\n",
        "\n",
        "1. Чтение данных:\n",
        "\n",
        "Загрузите данные из CSV файла в DataFrame. Скачать CSV нужно по ссылке - https://disk.yandex.ru/d/7Y7ZQgxUKizQsw"
      ],
      "metadata": {
        "id": "_LhMKRcwy70H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Read file Example\").getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\"/content/weather_data (2).csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Печать схемы DataFrame\n",
        "df.printSchema()\n",
        "\n",
        "# Показ первых 5 строк\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqu_U1qn_Sqf",
        "outputId": "fdb21286-3d4f-4d86-ecb4-49541d2f1282"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- station_id: string (nullable = true)\n",
            " |-- date: date (nullable = true)\n",
            " |-- temperature: double (nullable = true)\n",
            " |-- precipitation: double (nullable = true)\n",
            " |-- wind_speed: double (nullable = true)\n",
            "\n",
            "+----------+----------+------------------+------------------+-----------------+\n",
            "|station_id|      date|       temperature|     precipitation|       wind_speed|\n",
            "+----------+----------+------------------+------------------+-----------------+\n",
            "| station_7|2022-06-28|-6.751842212861652| 23.67004407474563|5.458999894629757|\n",
            "| station_4|2020-04-07| -9.57484426026233|2.9858244485444665|6.828505392085966|\n",
            "| station_8|2018-12-22| 19.34342035369938| 33.58211407730149|8.975576079892296|\n",
            "| station_5|2021-09-09|30.880953114964086|29.110437988411558|18.26465360842913|\n",
            "| station_7|2023-02-07|23.459048180599673|49.510444679381074|3.787868357696922|\n",
            "+----------+----------+------------------+------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите топ-5 самых жарких дней за все время наблюдений."
      ],
      "metadata": {
        "id": "kl59qNX-zWz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "\n",
        "df_new = df.orderBy((\"date\")).limit(5)\n",
        "df_new.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoplGIiuBwD9",
        "outputId": "b41f07f2-f54f-4cd9-938d-a4a63ab1ebbd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+-------------------+------------------+------------------+\n",
            "|station_id|      date|        temperature|     precipitation|        wind_speed|\n",
            "+----------+----------+-------------------+------------------+------------------+\n",
            "| station_6|2018-01-02| 29.741063952729462|22.192959421065055| 9.566709633411117|\n",
            "| station_7|2018-01-02|  7.865994173532567| 33.94488625389202| 17.45310144352111|\n",
            "| station_9|2018-01-02| 39.432761966208005| 5.721575930617928|  6.54841917466896|\n",
            "|station_10|2018-01-03|-13.283844378708181| 34.78987388277224|15.618387127721808|\n",
            "| station_9|2018-01-10| 12.947820176630358| 7.799043184946658| 5.319953861853159|\n",
            "+----------+----------+-------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите метеостанцию с наибольшим количеством осадков за последний год."
      ],
      "metadata": {
        "id": "qev-6-j2zZ54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year, col, month\n",
        "\n",
        "def_yeas = df.filter(year(col(\"date\")) == 2023)"
      ],
      "metadata": {
        "id": "H1kfflxHL_qn"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def_yeas.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG2WgdRSN8lv",
        "outputId": "bfe40f90-8265-487d-f7f5-3be4b2e3890a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+-------------------+------------------+------------------+\n",
            "|station_id|      date|        temperature|     precipitation|        wind_speed|\n",
            "+----------+----------+-------------------+------------------+------------------+\n",
            "| station_7|2023-02-07| 23.459048180599673|49.510444679381074| 3.787868357696922|\n",
            "| station_7|2023-04-13| 19.244547722319886|32.547866755903634|18.095326833602357|\n",
            "| station_5|2023-01-29|-11.971775823230677|42.359721951679084| 9.247823538250815|\n",
            "| station_6|2023-04-19| 14.928893786798334| 49.08266619262239| 14.34241136944387|\n",
            "|station_10|2023-10-24| -16.12299920935483| 36.24905849620262|14.594238129948444|\n",
            "| station_2|2023-06-14| 28.641155679175974|17.713388242052332|12.644763017357219|\n",
            "| station_2|2023-02-23|  3.543623291708471|31.045429510885402| 7.102632955076251|\n",
            "|station_10|2023-09-11|  6.596385246617096| 10.95587397349692|15.670001616905134|\n",
            "| station_8|2023-08-28| 19.542132052220843|10.697851934411846| 4.461241230855137|\n",
            "| station_5|2023-12-02|  7.716816200257345| 34.91555786137864| 8.470958319837926|\n",
            "| station_9|2023-04-05| 27.030560606060433| 19.63968879046717|  4.80141480975133|\n",
            "| station_8|2023-03-17|-15.877230048903934|22.911732519641692|  4.36519745387459|\n",
            "| station_1|2023-11-05|  5.457813153093287|39.067442030720315|19.788635315592632|\n",
            "| station_3|2023-02-02|  38.55945097592755|39.221042900170886|1.5287972207889533|\n",
            "| station_3|2023-07-01|   20.0410238827857|18.849277096314005| 17.91768362385319|\n",
            "| station_1|2023-06-30|-19.374338036155816|27.599515106036055|15.878587717199295|\n",
            "|station_10|2023-11-14|  37.58959108455574| 8.894406202451172| 3.120716226799538|\n",
            "| station_5|2023-06-25| 16.989983613705007|49.504318803374105| 5.515148088825626|\n",
            "| station_3|2023-08-17|-10.601693781571502|47.742349651923405|  4.08493517824335|\n",
            "| station_5|2023-04-05|-3.5725215491536098|13.777396960974169| 13.08320308572197|\n",
            "+----------+----------+-------------------+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum, avg"
      ],
      "metadata": {
        "id": "L6UPMHXEPw1b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precipitation_by_station = def_yeas.groupBy(\"station_id\").agg(sum(\"temperature\").alias(\"ww\"))\n",
        "precipitation_by_station.show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1HXkh5vOXnV",
        "outputId": "355c5ad7-9581-4f92-b661-250182c4363c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+\n",
            "|station_id|               ww|\n",
            "+----------+-----------------+\n",
            "| station_3|175.8907854025927|\n",
            "| station_2|224.0020087541091|\n",
            "| station_6|54.90319119179823|\n",
            "| station_1|44.37624664471266|\n",
            "+----------+-----------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подсчитайте среднюю температуру по месяцам за все время наблюдений."
      ],
      "metadata": {
        "id": "KPm8juGmzhon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def_moth = df.groupBy(month(col('date'))).agg(avg('temperature').alias(\"avg_temperature\")).orderBy('month(date)')\n",
        "def_moth.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6ks4VWpl7pS",
        "outputId": "44f7b3a6-2030-41d7-a269-cc2f030ab289"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|month(date)|   avg_temperature|\n",
            "+-----------+------------------+\n",
            "|          1|11.356518462550754|\n",
            "|          2| 9.067229891101926|\n",
            "|          3| 7.244080205633994|\n",
            "|          4|12.024529009744693|\n",
            "|          5| 9.902883346912718|\n",
            "|          6|13.421092297254138|\n",
            "|          7|6.1857183016954576|\n",
            "|          8|  10.9678002814186|\n",
            "|          9| 9.596744236573942|\n",
            "|         10|  9.09884344821895|\n",
            "|         11| 7.265889994697494|\n",
            "|         12|11.218592100674337|\n",
            "+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Самостоятельное задание  №2. Книги и авторы\n",
        "У вас есть два набора данных: информация о книгах и информация об авторах. Вам нужно объединить эти данные и провести анализ, чтобы найти различные статистики о книгах и авторах.\n",
        "\n",
        "Данные\n",
        "Таблица books:\n",
        "\n",
        "`book_id`: ID книги\n",
        "`title`: Название книги\n",
        "`author_id`: ID автора\n",
        "`genre`: Жанр книги\n",
        "`price`: Цена книги\n",
        "`publish_date`: Дата публикации (в формате YYYY-MM-DD)\n",
        "\n",
        "Таблица authors:\n",
        "\n",
        "`author_id`: ID автора\n",
        "`name`: Имя автора\n",
        "`birth_date`: Дата рождения автора (в формате YYYY-MM-DD)\n",
        "`country`: Страна автора"
      ],
      "metadata": {
        "id": "I8Cmez7pzmDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка данных по авторам и книгам"
      ],
      "metadata": {
        "id": "wBKtBAOiqql2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_author = spark.read.csv(\"/content/authors.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "hRP8nwh8px1A"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_book = spark.read.csv(\"/content/books.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "3cR0ViwYqbGH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_author.printSchema()\n",
        "df_author.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0RAOZxkqwes",
        "outputId": "ca701264-f15c-45b8-e87a-520c200a47e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- author_id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- birth_date: date (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            "\n",
            "+---------+---------+----------+---------+\n",
            "|author_id|     name|birth_date|  country|\n",
            "+---------+---------+----------+---------+\n",
            "|        1| Author_1|1960-12-31|    India|\n",
            "|        2| Author_2|1965-12-31|   Canada|\n",
            "|        3| Author_3|1970-12-31|      USA|\n",
            "|        4| Author_4|1975-12-31|       UK|\n",
            "|        5| Author_5|1980-12-31|      USA|\n",
            "|        6| Author_6|1985-12-31|      USA|\n",
            "|        7| Author_7|1990-12-31|      USA|\n",
            "|        8| Author_8|1995-12-31|Australia|\n",
            "|        9| Author_9|2000-12-31|Australia|\n",
            "|       10|Author_10|2005-12-31|    India|\n",
            "+---------+---------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_book.printSchema()\n",
        "df_book.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLP9UvfYq5fn",
        "outputId": "c20b531c-4c84-46e8-a330-eca4bddd217e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- book_id: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- author_id: integer (nullable = true)\n",
            " |-- genre: string (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- publish_date: date (nullable = true)\n",
            "\n",
            "+-------+-------+---------+-----------+-----+------------+\n",
            "|book_id|  title|author_id|      genre|price|publish_date|\n",
            "+-------+-------+---------+-----------+-----+------------+\n",
            "|      1| Book_1|        2|    Mystery|73.57|  1980-12-31|\n",
            "|      2| Book_2|        1|Non-Fiction| 41.1|  1982-12-31|\n",
            "|      3| Book_3|       10|    Fiction|10.63|  1984-12-31|\n",
            "|      4| Book_4|        9|Non-Fiction|46.31|  1986-12-31|\n",
            "|      5| Book_5|        7|    Science|31.13|  1988-12-31|\n",
            "|      6| Book_6|        4|Non-Fiction| 83.7|  1990-12-31|\n",
            "|      7| Book_7|        6|Non-Fiction|40.36|  1992-12-31|\n",
            "|      8| Book_8|        2|Non-Fiction|84.48|  1994-12-31|\n",
            "|      9| Book_9|        7|    Fantasy|10.05|  1996-12-31|\n",
            "|     10|Book_10|        2|    Science| 37.7|  1998-12-31|\n",
            "|     11|Book_11|       10|Non-Fiction| 31.7|  2000-12-31|\n",
            "|     12|Book_12|        8|Non-Fiction|31.02|  2002-12-31|\n",
            "|     13|Book_13|        8|Non-Fiction|16.14|  2004-12-31|\n",
            "|     14|Book_14|        1|    Fiction|26.84|  2006-12-31|\n",
            "|     15|Book_15|        8|    Fantasy| 60.0|  2008-12-31|\n",
            "|     16|Book_16|        2|    Fiction|36.22|  2010-12-31|\n",
            "|     17|Book_17|        6|    Fantasy|47.57|  2012-12-31|\n",
            "|     18|Book_18|        1|Non-Fiction|43.92|  2014-12-31|\n",
            "|     19|Book_19|        5|    Science|88.83|  2016-12-31|\n",
            "|     20|Book_20|        7|    Mystery|91.48|  2018-12-31|\n",
            "+-------+-------+---------+-----------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Объединение данных:\n",
        "\n",
        "Объедините таблицы books и authors по author_id."
      ],
      "metadata": {
        "id": "6NR3Ae0OrHoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_author_books = df_author.join(df_book, df_book.author_id == df_author.author_id, \"inner\")"
      ],
      "metadata": {
        "id": "alpjU15GrIWo"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_author_books.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UrVTNOdrjG8",
        "outputId": "468dedd7-1281-4761-dd7c-6e3dfab68a69"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+----------+---------+-------+-------+---------+-----------+-----+------------+\n",
            "|author_id|     name|birth_date|  country|book_id|  title|author_id|      genre|price|publish_date|\n",
            "+---------+---------+----------+---------+-------+-------+---------+-----------+-----+------------+\n",
            "|        2| Author_2|1965-12-31|   Canada|      1| Book_1|        2|    Mystery|73.57|  1980-12-31|\n",
            "|        1| Author_1|1960-12-31|    India|      2| Book_2|        1|Non-Fiction| 41.1|  1982-12-31|\n",
            "|       10|Author_10|2005-12-31|    India|      3| Book_3|       10|    Fiction|10.63|  1984-12-31|\n",
            "|        9| Author_9|2000-12-31|Australia|      4| Book_4|        9|Non-Fiction|46.31|  1986-12-31|\n",
            "|        7| Author_7|1990-12-31|      USA|      5| Book_5|        7|    Science|31.13|  1988-12-31|\n",
            "|        4| Author_4|1975-12-31|       UK|      6| Book_6|        4|Non-Fiction| 83.7|  1990-12-31|\n",
            "|        6| Author_6|1985-12-31|      USA|      7| Book_7|        6|Non-Fiction|40.36|  1992-12-31|\n",
            "|        2| Author_2|1965-12-31|   Canada|      8| Book_8|        2|Non-Fiction|84.48|  1994-12-31|\n",
            "|        7| Author_7|1990-12-31|      USA|      9| Book_9|        7|    Fantasy|10.05|  1996-12-31|\n",
            "|        2| Author_2|1965-12-31|   Canada|     10|Book_10|        2|    Science| 37.7|  1998-12-31|\n",
            "|       10|Author_10|2005-12-31|    India|     11|Book_11|       10|Non-Fiction| 31.7|  2000-12-31|\n",
            "|        8| Author_8|1995-12-31|Australia|     12|Book_12|        8|Non-Fiction|31.02|  2002-12-31|\n",
            "|        8| Author_8|1995-12-31|Australia|     13|Book_13|        8|Non-Fiction|16.14|  2004-12-31|\n",
            "|        1| Author_1|1960-12-31|    India|     14|Book_14|        1|    Fiction|26.84|  2006-12-31|\n",
            "|        8| Author_8|1995-12-31|Australia|     15|Book_15|        8|    Fantasy| 60.0|  2008-12-31|\n",
            "|        2| Author_2|1965-12-31|   Canada|     16|Book_16|        2|    Fiction|36.22|  2010-12-31|\n",
            "|        6| Author_6|1985-12-31|      USA|     17|Book_17|        6|    Fantasy|47.57|  2012-12-31|\n",
            "|        1| Author_1|1960-12-31|    India|     18|Book_18|        1|Non-Fiction|43.92|  2014-12-31|\n",
            "|        5| Author_5|1980-12-31|      USA|     19|Book_19|        5|    Science|88.83|  2016-12-31|\n",
            "|        7| Author_7|1990-12-31|      USA|     20|Book_20|        7|    Mystery|91.48|  2018-12-31|\n",
            "+---------+---------+----------+---------+-------+-------+---------+-----------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите топ-5 авторов, книги которых принесли наибольшую выручку."
      ],
      "metadata": {
        "id": "aWLjmiYJr3sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_author_books.groupBy(\"author_id\").agg(sum(\"price\")).alias(\"sum\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmosWfUCr2HE",
        "outputId": "3ce17459-ae1d-4398-f4c0-1264275cebfb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+\n",
            "|author_id|sum(price)|\n",
            "+---------+----------+\n",
            "|        1|    111.86|\n",
            "|        6|     87.93|\n",
            "|        5|     88.83|\n",
            "|        9|     46.31|\n",
            "|        4|      83.7|\n",
            "|        8|    107.16|\n",
            "|        7|    132.66|\n",
            "|       10|     42.33|\n",
            "|        2|    231.97|\n",
            "+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df_book = df_book.withColumnRenamed(\"author_id\", \"book_author_id\")\n",
        "\n",
        "df_author_books = df_author.join(df_book, df_book.book_author_id == df_author.author_id, \"inner\")\n",
        "\n",
        "df_author_books.show() # Выведет DataFrame с переименованным столбцом"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCvYlo45tS8h",
        "outputId": "f5f32c4d-6a13-4ed0-f769-de63cff3a399"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+----------+---------+-------+-------+--------------+-----------+-----+------------+\n",
            "|author_id|     name|birth_date|  country|book_id|  title|book_author_id|      genre|price|publish_date|\n",
            "+---------+---------+----------+---------+-------+-------+--------------+-----------+-----+------------+\n",
            "|        2| Author_2|1965-12-31|   Canada|      1| Book_1|             2|    Mystery|73.57|  1980-12-31|\n",
            "|        1| Author_1|1960-12-31|    India|      2| Book_2|             1|Non-Fiction| 41.1|  1982-12-31|\n",
            "|       10|Author_10|2005-12-31|    India|      3| Book_3|            10|    Fiction|10.63|  1984-12-31|\n",
            "|        9| Author_9|2000-12-31|Australia|      4| Book_4|             9|Non-Fiction|46.31|  1986-12-31|\n",
            "|        7| Author_7|1990-12-31|      USA|      5| Book_5|             7|    Science|31.13|  1988-12-31|\n",
            "|        4| Author_4|1975-12-31|       UK|      6| Book_6|             4|Non-Fiction| 83.7|  1990-12-31|\n",
            "|        6| Author_6|1985-12-31|      USA|      7| Book_7|             6|Non-Fiction|40.36|  1992-12-31|\n",
            "|        2| Author_2|1965-12-31|   Canada|      8| Book_8|             2|Non-Fiction|84.48|  1994-12-31|\n",
            "|        7| Author_7|1990-12-31|      USA|      9| Book_9|             7|    Fantasy|10.05|  1996-12-31|\n",
            "|        2| Author_2|1965-12-31|   Canada|     10|Book_10|             2|    Science| 37.7|  1998-12-31|\n",
            "|       10|Author_10|2005-12-31|    India|     11|Book_11|            10|Non-Fiction| 31.7|  2000-12-31|\n",
            "|        8| Author_8|1995-12-31|Australia|     12|Book_12|             8|Non-Fiction|31.02|  2002-12-31|\n",
            "|        8| Author_8|1995-12-31|Australia|     13|Book_13|             8|Non-Fiction|16.14|  2004-12-31|\n",
            "|        1| Author_1|1960-12-31|    India|     14|Book_14|             1|    Fiction|26.84|  2006-12-31|\n",
            "|        8| Author_8|1995-12-31|Australia|     15|Book_15|             8|    Fantasy| 60.0|  2008-12-31|\n",
            "|        2| Author_2|1965-12-31|   Canada|     16|Book_16|             2|    Fiction|36.22|  2010-12-31|\n",
            "|        6| Author_6|1985-12-31|      USA|     17|Book_17|             6|    Fantasy|47.57|  2012-12-31|\n",
            "|        1| Author_1|1960-12-31|    India|     18|Book_18|             1|Non-Fiction|43.92|  2014-12-31|\n",
            "|        5| Author_5|1980-12-31|      USA|     19|Book_19|             5|    Science|88.83|  2016-12-31|\n",
            "|        7| Author_7|1990-12-31|      USA|     20|Book_20|             7|    Mystery|91.48|  2018-12-31|\n",
            "+---------+---------+----------+---------+-------+-------+--------------+-----------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите количество книг в каждом жанре."
      ],
      "metadata": {
        "id": "qnoiqDY2xFFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count, desc"
      ],
      "metadata": {
        "id": "Ypy3iQ_dwkrg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_book.groupBy(\"genre\").agg(count(\"genre\").alias(\"number\")).orderBy(desc(\"number\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YctxRpMpt7k8",
        "outputId": "5866912a-4378-4f08-a4e4-18009fdefe28"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------+\n",
            "|      genre|number|\n",
            "+-----------+------+\n",
            "|Non-Fiction|     9|\n",
            "|    Science|     3|\n",
            "|    Fiction|     3|\n",
            "|    Fantasy|     3|\n",
            "|    Mystery|     2|\n",
            "+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подсчитайте среднюю цену книг по каждому автору."
      ],
      "metadata": {
        "id": "knVQ76UfxIiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_author_books.groupBy(\"name\").agg(avg(\"price\").alias(\"PRICE\")).orderBy(desc(\"PRICE\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrQD1Oi-xFxQ",
        "outputId": "39d4281f-72b4-4f91-fe37-645f8e330441"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------+\n",
            "|     name|            PRICE|\n",
            "+---------+-----------------+\n",
            "| Author_5|            88.83|\n",
            "| Author_4|             83.7|\n",
            "| Author_2|          57.9925|\n",
            "| Author_9|            46.31|\n",
            "| Author_7|            44.22|\n",
            "| Author_6|           43.965|\n",
            "| Author_1|37.28666666666667|\n",
            "| Author_8|            35.72|\n",
            "|Author_10|           21.165|\n",
            "+---------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите книги, опубликованные после 2000 года, и отсортируйте их по цене."
      ],
      "metadata": {
        "id": "6S-FKJeMxpe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_author_books.filter(year(col(\"publish_date\")) > 2000).orderBy(desc(\"price\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DMIOdPnxseC",
        "outputId": "0933e722-d5d8-463a-a137-66cb84b6075f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+----------+---------+-------+-------+--------------+-----------+-----+------------+\n",
            "|author_id|    name|birth_date|  country|book_id|  title|book_author_id|      genre|price|publish_date|\n",
            "+---------+--------+----------+---------+-------+-------+--------------+-----------+-----+------------+\n",
            "|        7|Author_7|1990-12-31|      USA|     20|Book_20|             7|    Mystery|91.48|  2018-12-31|\n",
            "|        5|Author_5|1980-12-31|      USA|     19|Book_19|             5|    Science|88.83|  2016-12-31|\n",
            "|        8|Author_8|1995-12-31|Australia|     15|Book_15|             8|    Fantasy| 60.0|  2008-12-31|\n",
            "|        6|Author_6|1985-12-31|      USA|     17|Book_17|             6|    Fantasy|47.57|  2012-12-31|\n",
            "|        1|Author_1|1960-12-31|    India|     18|Book_18|             1|Non-Fiction|43.92|  2014-12-31|\n",
            "|        2|Author_2|1965-12-31|   Canada|     16|Book_16|             2|    Fiction|36.22|  2010-12-31|\n",
            "|        8|Author_8|1995-12-31|Australia|     12|Book_12|             8|Non-Fiction|31.02|  2002-12-31|\n",
            "|        1|Author_1|1960-12-31|    India|     14|Book_14|             1|    Fiction|26.84|  2006-12-31|\n",
            "|        8|Author_8|1995-12-31|Australia|     13|Book_13|             8|Non-Fiction|16.14|  2004-12-31|\n",
            "+---------+--------+----------+---------+-------+-------+--------------+-----------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}