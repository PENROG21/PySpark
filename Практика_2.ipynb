{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtcbAEQfbwFdGt48Hvm9iF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PENROG21/PySpark/blob/main/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D0%BA%D0%B0_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполнение практических заданий"
      ],
      "metadata": {
        "id": "ofdu49_my1Gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импорт"
      ],
      "metadata": {
        "id": "nF04K6BTy6T6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioU_ZUOa_Nk6",
        "outputId": "9e956401-1eb6-4091-f70a-1a0295ee1936"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Самостоятельное задание  №1. Погода\n",
        "У вас есть данные о погоде за несколько лет, собранные из различных метеостанций. Ваша задача — проанализировать эти данные, чтобы выявить тренды и аномалии.\n",
        "\n",
        "Данные о погоде представлены в формате CSV и содержат следующие столбцы:\n",
        "\n",
        "`station_id`: ID метеостанции\n",
        "`date`: Дата наблюдения (в формате YYYY-MM-DD)\n",
        "`temperature`: Средняя температура в градусах Цельсия\n",
        "\n",
        "`precipitation`: Количество осадков в миллиметрах\n",
        "\n",
        "`wind_speed`: Средняя скорость ветра в метрах в секунду"
      ],
      "metadata": {
        "id": "-BbF07KjzDZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выполните следующие пункты по порядку.\n",
        "\n",
        "1. Чтение данных:\n",
        "\n",
        "Загрузите данные из CSV файла в DataFrame. Скачать CSV нужно по ссылке - https://disk.yandex.ru/d/7Y7ZQgxUKizQsw"
      ],
      "metadata": {
        "id": "_LhMKRcwy70H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"Read file Example\").getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\"/content/weather_data (2).csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Печать схемы DataFrame\n",
        "df.printSchema()\n",
        "\n",
        "# Показ первых 5 строк\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqu_U1qn_Sqf",
        "outputId": "fdb21286-3d4f-4d86-ecb4-49541d2f1282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- station_id: string (nullable = true)\n",
            " |-- date: date (nullable = true)\n",
            " |-- temperature: double (nullable = true)\n",
            " |-- precipitation: double (nullable = true)\n",
            " |-- wind_speed: double (nullable = true)\n",
            "\n",
            "+----------+----------+------------------+------------------+-----------------+\n",
            "|station_id|      date|       temperature|     precipitation|       wind_speed|\n",
            "+----------+----------+------------------+------------------+-----------------+\n",
            "| station_7|2022-06-28|-6.751842212861652| 23.67004407474563|5.458999894629757|\n",
            "| station_4|2020-04-07| -9.57484426026233|2.9858244485444665|6.828505392085966|\n",
            "| station_8|2018-12-22| 19.34342035369938| 33.58211407730149|8.975576079892296|\n",
            "| station_5|2021-09-09|30.880953114964086|29.110437988411558|18.26465360842913|\n",
            "| station_7|2023-02-07|23.459048180599673|49.510444679381074|3.787868357696922|\n",
            "+----------+----------+------------------+------------------+-----------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите топ-5 самых жарких дней за все время наблюдений."
      ],
      "metadata": {
        "id": "kl59qNX-zWz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import desc\n",
        "\n",
        "\n",
        "df_new = df.orderBy((\"date\")).limit(5)\n",
        "df_new.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoplGIiuBwD9",
        "outputId": "b41f07f2-f54f-4cd9-938d-a4a63ab1ebbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+-------------------+------------------+------------------+\n",
            "|station_id|      date|        temperature|     precipitation|        wind_speed|\n",
            "+----------+----------+-------------------+------------------+------------------+\n",
            "| station_6|2018-01-02| 29.741063952729462|22.192959421065055| 9.566709633411117|\n",
            "| station_7|2018-01-02|  7.865994173532567| 33.94488625389202| 17.45310144352111|\n",
            "| station_9|2018-01-02| 39.432761966208005| 5.721575930617928|  6.54841917466896|\n",
            "|station_10|2018-01-03|-13.283844378708181| 34.78987388277224|15.618387127721808|\n",
            "| station_9|2018-01-10| 12.947820176630358| 7.799043184946658| 5.319953861853159|\n",
            "+----------+----------+-------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите метеостанцию с наибольшим количеством осадков за последний год."
      ],
      "metadata": {
        "id": "qev-6-j2zZ54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year, col, month\n",
        "\n",
        "def_yeas = df.filter(year(col(\"date\")) == 2023)"
      ],
      "metadata": {
        "id": "H1kfflxHL_qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def_yeas.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG2WgdRSN8lv",
        "outputId": "bfe40f90-8265-487d-f7f5-3be4b2e3890a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+-------------------+------------------+------------------+\n",
            "|station_id|      date|        temperature|     precipitation|        wind_speed|\n",
            "+----------+----------+-------------------+------------------+------------------+\n",
            "| station_7|2023-02-07| 23.459048180599673|49.510444679381074| 3.787868357696922|\n",
            "| station_7|2023-04-13| 19.244547722319886|32.547866755903634|18.095326833602357|\n",
            "| station_5|2023-01-29|-11.971775823230677|42.359721951679084| 9.247823538250815|\n",
            "| station_6|2023-04-19| 14.928893786798334| 49.08266619262239| 14.34241136944387|\n",
            "|station_10|2023-10-24| -16.12299920935483| 36.24905849620262|14.594238129948444|\n",
            "| station_2|2023-06-14| 28.641155679175974|17.713388242052332|12.644763017357219|\n",
            "| station_2|2023-02-23|  3.543623291708471|31.045429510885402| 7.102632955076251|\n",
            "|station_10|2023-09-11|  6.596385246617096| 10.95587397349692|15.670001616905134|\n",
            "| station_8|2023-08-28| 19.542132052220843|10.697851934411846| 4.461241230855137|\n",
            "| station_5|2023-12-02|  7.716816200257345| 34.91555786137864| 8.470958319837926|\n",
            "| station_9|2023-04-05| 27.030560606060433| 19.63968879046717|  4.80141480975133|\n",
            "| station_8|2023-03-17|-15.877230048903934|22.911732519641692|  4.36519745387459|\n",
            "| station_1|2023-11-05|  5.457813153093287|39.067442030720315|19.788635315592632|\n",
            "| station_3|2023-02-02|  38.55945097592755|39.221042900170886|1.5287972207889533|\n",
            "| station_3|2023-07-01|   20.0410238827857|18.849277096314005| 17.91768362385319|\n",
            "| station_1|2023-06-30|-19.374338036155816|27.599515106036055|15.878587717199295|\n",
            "|station_10|2023-11-14|  37.58959108455574| 8.894406202451172| 3.120716226799538|\n",
            "| station_5|2023-06-25| 16.989983613705007|49.504318803374105| 5.515148088825626|\n",
            "| station_3|2023-08-17|-10.601693781571502|47.742349651923405|  4.08493517824335|\n",
            "| station_5|2023-04-05|-3.5725215491536098|13.777396960974169| 13.08320308572197|\n",
            "+----------+----------+-------------------+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum, avg"
      ],
      "metadata": {
        "id": "L6UPMHXEPw1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precipitation_by_station = def_yeas.groupBy(\"station_id\").agg(sum(\"temperature\").alias(\"ww\"))\n",
        "precipitation_by_station.show(4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1HXkh5vOXnV",
        "outputId": "355c5ad7-9581-4f92-b661-250182c4363c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+\n",
            "|station_id|               ww|\n",
            "+----------+-----------------+\n",
            "| station_3|175.8907854025927|\n",
            "| station_2|224.0020087541091|\n",
            "| station_6|54.90319119179823|\n",
            "| station_1|44.37624664471266|\n",
            "+----------+-----------------+\n",
            "only showing top 4 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подсчитайте среднюю температуру по месяцам за все время наблюдений."
      ],
      "metadata": {
        "id": "KPm8juGmzhon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def_moth = df.groupBy(month(col('date'))).agg(avg('temperature').alias(\"avg_temperature\")).orderBy('month(date)')\n",
        "def_moth.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6ks4VWpl7pS",
        "outputId": "44f7b3a6-2030-41d7-a269-cc2f030ab289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+\n",
            "|month(date)|   avg_temperature|\n",
            "+-----------+------------------+\n",
            "|          1|11.356518462550754|\n",
            "|          2| 9.067229891101926|\n",
            "|          3| 7.244080205633994|\n",
            "|          4|12.024529009744693|\n",
            "|          5| 9.902883346912718|\n",
            "|          6|13.421092297254138|\n",
            "|          7|6.1857183016954576|\n",
            "|          8|  10.9678002814186|\n",
            "|          9| 9.596744236573942|\n",
            "|         10|  9.09884344821895|\n",
            "|         11| 7.265889994697494|\n",
            "|         12|11.218592100674337|\n",
            "+-----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Самостоятельное задание  №2. Книги и авторы\n",
        "У вас есть два набора данных: информация о книгах и информация об авторах. Вам нужно объединить эти данные и провести анализ, чтобы найти различные статистики о книгах и авторах.\n",
        "\n",
        "Данные\n",
        "Таблица books:\n",
        "\n",
        "`book_id`: ID книги\n",
        "`title`: Название книги\n",
        "`author_id`: ID автора\n",
        "`genre`: Жанр книги\n",
        "`price`: Цена книги\n",
        "`publish_date`: Дата публикации (в формате YYYY-MM-DD)\n",
        "\n",
        "Таблица authors:\n",
        "\n",
        "`author_id`: ID автора\n",
        "`name`: Имя автора\n",
        "`birth_date`: Дата рождения автора (в формате YYYY-MM-DD)\n",
        "`country`: Страна автора"
      ],
      "metadata": {
        "id": "I8Cmez7pzmDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка данных по авторам и книгам"
      ],
      "metadata": {
        "id": "wBKtBAOiqql2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_author = spark.read.csv(\"/content/authors.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "hRP8nwh8px1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_book = spark.read.csv(\"/content/books.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "3cR0ViwYqbGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_author.printSchema()\n",
        "df_author.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0RAOZxkqwes",
        "outputId": "ca701264-f15c-45b8-e87a-520c200a47e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- author_id: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- birth_date: date (nullable = true)\n",
            " |-- country: string (nullable = true)\n",
            "\n",
            "+---------+---------+----------+---------+\n",
            "|author_id|     name|birth_date|  country|\n",
            "+---------+---------+----------+---------+\n",
            "|        1| Author_1|1960-12-31|    India|\n",
            "|        2| Author_2|1965-12-31|   Canada|\n",
            "|        3| Author_3|1970-12-31|      USA|\n",
            "|        4| Author_4|1975-12-31|       UK|\n",
            "|        5| Author_5|1980-12-31|      USA|\n",
            "|        6| Author_6|1985-12-31|      USA|\n",
            "|        7| Author_7|1990-12-31|      USA|\n",
            "|        8| Author_8|1995-12-31|Australia|\n",
            "|        9| Author_9|2000-12-31|Australia|\n",
            "|       10|Author_10|2005-12-31|    India|\n",
            "+---------+---------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_book.printSchema()\n",
        "df_book.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLP9UvfYq5fn",
        "outputId": "c20b531c-4c84-46e8-a330-eca4bddd217e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- book_id: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- author_id: integer (nullable = true)\n",
            " |-- genre: string (nullable = true)\n",
            " |-- price: double (nullable = true)\n",
            " |-- publish_date: date (nullable = true)\n",
            "\n",
            "+-------+-------+---------+-----------+-----+------------+\n",
            "|book_id|  title|author_id|      genre|price|publish_date|\n",
            "+-------+-------+---------+-----------+-----+------------+\n",
            "|      1| Book_1|        2|    Mystery|73.57|  1980-12-31|\n",
            "|      2| Book_2|        1|Non-Fiction| 41.1|  1982-12-31|\n",
            "|      3| Book_3|       10|    Fiction|10.63|  1984-12-31|\n",
            "|      4| Book_4|        9|Non-Fiction|46.31|  1986-12-31|\n",
            "|      5| Book_5|        7|    Science|31.13|  1988-12-31|\n",
            "|      6| Book_6|        4|Non-Fiction| 83.7|  1990-12-31|\n",
            "|      7| Book_7|        6|Non-Fiction|40.36|  1992-12-31|\n",
            "|      8| Book_8|        2|Non-Fiction|84.48|  1994-12-31|\n",
            "|      9| Book_9|        7|    Fantasy|10.05|  1996-12-31|\n",
            "|     10|Book_10|        2|    Science| 37.7|  1998-12-31|\n",
            "|     11|Book_11|       10|Non-Fiction| 31.7|  2000-12-31|\n",
            "|     12|Book_12|        8|Non-Fiction|31.02|  2002-12-31|\n",
            "|     13|Book_13|        8|Non-Fiction|16.14|  2004-12-31|\n",
            "|     14|Book_14|        1|    Fiction|26.84|  2006-12-31|\n",
            "|     15|Book_15|        8|    Fantasy| 60.0|  2008-12-31|\n",
            "|     16|Book_16|        2|    Fiction|36.22|  2010-12-31|\n",
            "|     17|Book_17|        6|    Fantasy|47.57|  2012-12-31|\n",
            "|     18|Book_18|        1|Non-Fiction|43.92|  2014-12-31|\n",
            "|     19|Book_19|        5|    Science|88.83|  2016-12-31|\n",
            "|     20|Book_20|        7|    Mystery|91.48|  2018-12-31|\n",
            "+-------+-------+---------+-----------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Объединение данных:\n",
        "\n",
        "Объедините таблицы books и authors по author_id."
      ],
      "metadata": {
        "id": "6NR3Ae0OrHoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_author_books = df_author.join(df_book, df_book.author_id == df_author.author_id, \"inner\")"
      ],
      "metadata": {
        "id": "alpjU15GrIWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_author_books.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UrVTNOdrjG8",
        "outputId": "468dedd7-1281-4761-dd7c-6e3dfab68a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+----------+---------+-------+-------+---------+-----------+-----+------------+\n",
            "|author_id|     name|birth_date|  country|book_id|  title|author_id|      genre|price|publish_date|\n",
            "+---------+---------+----------+---------+-------+-------+---------+-----------+-----+------------+\n",
            "|        2| Author_2|1965-12-31|   Canada|      1| Book_1|        2|    Mystery|73.57|  1980-12-31|\n",
            "|        1| Author_1|1960-12-31|    India|      2| Book_2|        1|Non-Fiction| 41.1|  1982-12-31|\n",
            "|       10|Author_10|2005-12-31|    India|      3| Book_3|       10|    Fiction|10.63|  1984-12-31|\n",
            "|        9| Author_9|2000-12-31|Australia|      4| Book_4|        9|Non-Fiction|46.31|  1986-12-31|\n",
            "|        7| Author_7|1990-12-31|      USA|      5| Book_5|        7|    Science|31.13|  1988-12-31|\n",
            "|        4| Author_4|1975-12-31|       UK|      6| Book_6|        4|Non-Fiction| 83.7|  1990-12-31|\n",
            "|        6| Author_6|1985-12-31|      USA|      7| Book_7|        6|Non-Fiction|40.36|  1992-12-31|\n",
            "|        2| Author_2|1965-12-31|   Canada|      8| Book_8|        2|Non-Fiction|84.48|  1994-12-31|\n",
            "|        7| Author_7|1990-12-31|      USA|      9| Book_9|        7|    Fantasy|10.05|  1996-12-31|\n",
            "|        2| Author_2|1965-12-31|   Canada|     10|Book_10|        2|    Science| 37.7|  1998-12-31|\n",
            "|       10|Author_10|2005-12-31|    India|     11|Book_11|       10|Non-Fiction| 31.7|  2000-12-31|\n",
            "|        8| Author_8|1995-12-31|Australia|     12|Book_12|        8|Non-Fiction|31.02|  2002-12-31|\n",
            "|        8| Author_8|1995-12-31|Australia|     13|Book_13|        8|Non-Fiction|16.14|  2004-12-31|\n",
            "|        1| Author_1|1960-12-31|    India|     14|Book_14|        1|    Fiction|26.84|  2006-12-31|\n",
            "|        8| Author_8|1995-12-31|Australia|     15|Book_15|        8|    Fantasy| 60.0|  2008-12-31|\n",
            "|        2| Author_2|1965-12-31|   Canada|     16|Book_16|        2|    Fiction|36.22|  2010-12-31|\n",
            "|        6| Author_6|1985-12-31|      USA|     17|Book_17|        6|    Fantasy|47.57|  2012-12-31|\n",
            "|        1| Author_1|1960-12-31|    India|     18|Book_18|        1|Non-Fiction|43.92|  2014-12-31|\n",
            "|        5| Author_5|1980-12-31|      USA|     19|Book_19|        5|    Science|88.83|  2016-12-31|\n",
            "|        7| Author_7|1990-12-31|      USA|     20|Book_20|        7|    Mystery|91.48|  2018-12-31|\n",
            "+---------+---------+----------+---------+-------+-------+---------+-----------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите топ-5 авторов, книги которых принесли наибольшую выручку."
      ],
      "metadata": {
        "id": "aWLjmiYJr3sp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_author_books.groupBy(\"author_id\").agg(sum(\"price\")).alias(\"sum\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmosWfUCr2HE",
        "outputId": "3ce17459-ae1d-4398-f4c0-1264275cebfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+\n",
            "|author_id|sum(price)|\n",
            "+---------+----------+\n",
            "|        1|    111.86|\n",
            "|        6|     87.93|\n",
            "|        5|     88.83|\n",
            "|        9|     46.31|\n",
            "|        4|      83.7|\n",
            "|        8|    107.16|\n",
            "|        7|    132.66|\n",
            "|       10|     42.33|\n",
            "|        2|    231.97|\n",
            "+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df_book = df_book.withColumnRenamed(\"author_id\", \"book_author_id\")\n",
        "\n",
        "df_author_books = df_author.join(df_book, df_book.book_author_id == df_author.author_id, \"inner\")\n",
        "\n",
        "df_author_books.show() # Выведет DataFrame с переименованным столбцом"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCvYlo45tS8h",
        "outputId": "f5f32c4d-6a13-4ed0-f769-de63cff3a399"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+----------+---------+-------+-------+--------------+-----------+-----+------------+\n",
            "|author_id|     name|birth_date|  country|book_id|  title|book_author_id|      genre|price|publish_date|\n",
            "+---------+---------+----------+---------+-------+-------+--------------+-----------+-----+------------+\n",
            "|        2| Author_2|1965-12-31|   Canada|      1| Book_1|             2|    Mystery|73.57|  1980-12-31|\n",
            "|        1| Author_1|1960-12-31|    India|      2| Book_2|             1|Non-Fiction| 41.1|  1982-12-31|\n",
            "|       10|Author_10|2005-12-31|    India|      3| Book_3|            10|    Fiction|10.63|  1984-12-31|\n",
            "|        9| Author_9|2000-12-31|Australia|      4| Book_4|             9|Non-Fiction|46.31|  1986-12-31|\n",
            "|        7| Author_7|1990-12-31|      USA|      5| Book_5|             7|    Science|31.13|  1988-12-31|\n",
            "|        4| Author_4|1975-12-31|       UK|      6| Book_6|             4|Non-Fiction| 83.7|  1990-12-31|\n",
            "|        6| Author_6|1985-12-31|      USA|      7| Book_7|             6|Non-Fiction|40.36|  1992-12-31|\n",
            "|        2| Author_2|1965-12-31|   Canada|      8| Book_8|             2|Non-Fiction|84.48|  1994-12-31|\n",
            "|        7| Author_7|1990-12-31|      USA|      9| Book_9|             7|    Fantasy|10.05|  1996-12-31|\n",
            "|        2| Author_2|1965-12-31|   Canada|     10|Book_10|             2|    Science| 37.7|  1998-12-31|\n",
            "|       10|Author_10|2005-12-31|    India|     11|Book_11|            10|Non-Fiction| 31.7|  2000-12-31|\n",
            "|        8| Author_8|1995-12-31|Australia|     12|Book_12|             8|Non-Fiction|31.02|  2002-12-31|\n",
            "|        8| Author_8|1995-12-31|Australia|     13|Book_13|             8|Non-Fiction|16.14|  2004-12-31|\n",
            "|        1| Author_1|1960-12-31|    India|     14|Book_14|             1|    Fiction|26.84|  2006-12-31|\n",
            "|        8| Author_8|1995-12-31|Australia|     15|Book_15|             8|    Fantasy| 60.0|  2008-12-31|\n",
            "|        2| Author_2|1965-12-31|   Canada|     16|Book_16|             2|    Fiction|36.22|  2010-12-31|\n",
            "|        6| Author_6|1985-12-31|      USA|     17|Book_17|             6|    Fantasy|47.57|  2012-12-31|\n",
            "|        1| Author_1|1960-12-31|    India|     18|Book_18|             1|Non-Fiction|43.92|  2014-12-31|\n",
            "|        5| Author_5|1980-12-31|      USA|     19|Book_19|             5|    Science|88.83|  2016-12-31|\n",
            "|        7| Author_7|1990-12-31|      USA|     20|Book_20|             7|    Mystery|91.48|  2018-12-31|\n",
            "+---------+---------+----------+---------+-------+-------+--------------+-----------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите количество книг в каждом жанре."
      ],
      "metadata": {
        "id": "qnoiqDY2xFFe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count, desc"
      ],
      "metadata": {
        "id": "Ypy3iQ_dwkrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_book.groupBy(\"genre\").agg(count(\"genre\").alias(\"number\")).orderBy(desc(\"number\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YctxRpMpt7k8",
        "outputId": "5866912a-4378-4f08-a4e4-18009fdefe28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------+\n",
            "|      genre|number|\n",
            "+-----------+------+\n",
            "|Non-Fiction|     9|\n",
            "|    Science|     3|\n",
            "|    Fiction|     3|\n",
            "|    Fantasy|     3|\n",
            "|    Mystery|     2|\n",
            "+-----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подсчитайте среднюю цену книг по каждому автору."
      ],
      "metadata": {
        "id": "knVQ76UfxIiK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_author_books.groupBy(\"name\").agg(avg(\"price\").alias(\"PRICE\")).orderBy(desc(\"PRICE\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrQD1Oi-xFxQ",
        "outputId": "39d4281f-72b4-4f91-fe37-645f8e330441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------+\n",
            "|     name|            PRICE|\n",
            "+---------+-----------------+\n",
            "| Author_5|            88.83|\n",
            "| Author_4|             83.7|\n",
            "| Author_2|          57.9925|\n",
            "| Author_9|            46.31|\n",
            "| Author_7|            44.22|\n",
            "| Author_6|           43.965|\n",
            "| Author_1|37.28666666666667|\n",
            "| Author_8|            35.72|\n",
            "|Author_10|           21.165|\n",
            "+---------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите книги, опубликованные после 2000 года, и отсортируйте их по цене."
      ],
      "metadata": {
        "id": "6S-FKJeMxpe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_author_books.filter(year(col(\"publish_date\")) > 2000).orderBy(desc(\"price\")).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DMIOdPnxseC",
        "outputId": "0933e722-d5d8-463a-a137-66cb84b6075f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+----------+---------+-------+-------+--------------+-----------+-----+------------+\n",
            "|author_id|    name|birth_date|  country|book_id|  title|book_author_id|      genre|price|publish_date|\n",
            "+---------+--------+----------+---------+-------+-------+--------------+-----------+-----+------------+\n",
            "|        7|Author_7|1990-12-31|      USA|     20|Book_20|             7|    Mystery|91.48|  2018-12-31|\n",
            "|        5|Author_5|1980-12-31|      USA|     19|Book_19|             5|    Science|88.83|  2016-12-31|\n",
            "|        8|Author_8|1995-12-31|Australia|     15|Book_15|             8|    Fantasy| 60.0|  2008-12-31|\n",
            "|        6|Author_6|1985-12-31|      USA|     17|Book_17|             6|    Fantasy|47.57|  2012-12-31|\n",
            "|        1|Author_1|1960-12-31|    India|     18|Book_18|             1|Non-Fiction|43.92|  2014-12-31|\n",
            "|        2|Author_2|1965-12-31|   Canada|     16|Book_16|             2|    Fiction|36.22|  2010-12-31|\n",
            "|        8|Author_8|1995-12-31|Australia|     12|Book_12|             8|Non-Fiction|31.02|  2002-12-31|\n",
            "|        1|Author_1|1960-12-31|    India|     14|Book_14|             1|    Fiction|26.84|  2006-12-31|\n",
            "|        8|Author_8|1995-12-31|Australia|     13|Book_13|             8|Non-Fiction|16.14|  2004-12-31|\n",
            "+---------+--------+----------+---------+-------+-------+--------------+-----------+-----+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Самостоятельное задание  №3. Фильмы и актеры. С использованием временных таблиц и SQL\n",
        "У вас есть три набора данных: информация о фильмах и информация о актерах, снявшихся в фильмах, а также id фильма и id актера. Вам нужно объединить эти данные и провести анализ с использованием Spark SQL."
      ],
      "metadata": {
        "id": "N3VoEPxgvBSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данные\n",
        "Таблица movies:\n",
        "\n",
        "movie_id: ID фильма\n",
        "title: Название фильма\n",
        "genre: Жанр фильма\n",
        "release_date: Дата выхода (в формате YYYY-MM-DD)\n",
        "budget: Бюджет фильма\n",
        "Таблица actors:\n",
        "\n",
        "actor_id: ID актера\n",
        "name: Имя актера\n",
        "birth_date: Дата рождения актера (в формате YYYY-MM-DD)\n",
        "country: Страна актера\n",
        "Таблица movie_actors:\n",
        "\n",
        "movie_id: ID фильма\n",
        "actor_id: ID актера\n",
        "Выполните следующие пункты по порядку.\n",
        "\n",
        "1. Чтение данных:\n",
        "\n",
        "Загрузите данные из CSV файлов в Spark DataFrame. Все что необходимо скачать находится по ссылке - https://disk.yandex.ru/d/EJU5clkFkhWklA"
      ],
      "metadata": {
        "id": "JSkeVrPPD17D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"nomber 3\").getOrCreate()\n",
        "\n",
        "df_actors = spark.read.csv(\"/content/actors.csv\", header=True, inferSchema=True)\n",
        "df_movie_actors = spark.read.csv(\"/content/movie_actors.csv\", header=True, inferSchema=True)\n",
        "df_movies = spark.read.csv(\"/content/movies.csv\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "ZH9GfmLvvAh2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Создание временных таблиц:\n",
        "\n",
        "Создайте временные таблицы для данных о фильмах, актерах и связях между ними."
      ],
      "metadata": {
        "id": "QKGTIkZmwklB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_actors.createOrReplaceTempView(\"actors\")\n",
        "df_movie_actors.createOrReplaceTempView(\"movie_actors\")\n",
        "df_movies.createOrReplaceTempView(\"movies\")"
      ],
      "metadata": {
        "id": "En3TMYvnxP-A"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_actors.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi96DxuCCZ4r",
        "outputId": "7a62cc76-26a7-4424-d28a-657ca34c513a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+----------+---------+\n",
            "|actor_id|    name|birth_date|  country|\n",
            "+--------+--------+----------+---------+\n",
            "|       1| Actor_1|1960-12-31|   Canada|\n",
            "|       2| Actor_2|1962-12-31|       UK|\n",
            "|       3| Actor_3|1964-12-31|       UK|\n",
            "|       4| Actor_4|1966-12-31|       UK|\n",
            "|       5| Actor_5|1968-12-31|    India|\n",
            "|       6| Actor_6|1970-12-31|      USA|\n",
            "|       7| Actor_7|1972-12-31|    India|\n",
            "|       8| Actor_8|1974-12-31|Australia|\n",
            "|       9| Actor_9|1976-12-31|      USA|\n",
            "|      10|Actor_10|1978-12-31|Australia|\n",
            "|      11|Actor_11|1980-12-31|      USA|\n",
            "|      12|Actor_12|1982-12-31|    India|\n",
            "|      13|Actor_13|1984-12-31|       UK|\n",
            "|      14|Actor_14|1986-12-31|   Canada|\n",
            "|      15|Actor_15|1988-12-31|       UK|\n",
            "|      16|Actor_16|1990-12-31|    India|\n",
            "|      17|Actor_17|1992-12-31|      USA|\n",
            "|      18|Actor_18|1994-12-31|       UK|\n",
            "|      19|Actor_19|1996-12-31|    India|\n",
            "|      20|Actor_20|1998-12-31|Australia|\n",
            "+--------+--------+----------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_movie_actors.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjLyMgzgyVtP",
        "outputId": "2ae1fed8-edb0-4249-a0bd-e7247ae17ad2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+\n",
            "|movie_id|actor_id|\n",
            "+--------+--------+\n",
            "|       1|      25|\n",
            "|      16|       5|\n",
            "|       6|      16|\n",
            "|      16|      11|\n",
            "|      14|      21|\n",
            "|       3|       6|\n",
            "|      15|       9|\n",
            "|       3|      13|\n",
            "|       2|      24|\n",
            "|       1|       8|\n",
            "|       9|      14|\n",
            "|       9|      24|\n",
            "|       7|       1|\n",
            "|       3|      17|\n",
            "|      18|      24|\n",
            "|      11|       5|\n",
            "|       7|      25|\n",
            "|       9|       2|\n",
            "|       1|      25|\n",
            "|      14|      28|\n",
            "+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_movies.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjdmg7pcyjPn",
        "outputId": "d976bc9e-0ad4-46bc-a03d-e59e48f207d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+------------+-------------+\n",
            "|movie_id|   title| genre|release_date|       budget|\n",
            "+--------+--------+------+------------+-------------+\n",
            "|       1| Movie_1|Horror|  2000-12-31|8.660058311E7|\n",
            "|       2| Movie_2|Comedy|  2001-12-31|1.274740083E7|\n",
            "|       3| Movie_3|Action|  2002-12-31| 1.80157747E7|\n",
            "|       4| Movie_4| Drama|  2003-12-31|4.817612061E7|\n",
            "|       5| Movie_5| Drama|  2004-12-31| 7.40501611E7|\n",
            "|       6| Movie_6|Action|  2005-12-31|1.476121831E7|\n",
            "|       7| Movie_7| Drama|  2006-12-31|4.456703643E7|\n",
            "|       8| Movie_8| Drama|  2007-12-31|4.880227617E7|\n",
            "|       9| Movie_9|Action|  2008-12-31|2.201627853E7|\n",
            "|      10|Movie_10|Action|  2009-12-31|1.244027929E7|\n",
            "|      11|Movie_11|Comedy|  2010-12-31|8.380567138E7|\n",
            "|      12|Movie_12|Comedy|  2011-12-31|5.074409933E7|\n",
            "|      13|Movie_13|Action|  2012-12-31|   2423742.36|\n",
            "|      14|Movie_14|Sci-Fi|  2013-12-31|8.049514883E7|\n",
            "|      15|Movie_15| Drama|  2014-12-31|9.809858674E7|\n",
            "|      16|Movie_16|Comedy|  2015-12-31|6.098669335E7|\n",
            "|      17|Movie_17| Drama|  2016-12-31|5.086713032E7|\n",
            "|      18|Movie_18|Horror|  2017-12-31|8.796317044E7|\n",
            "|      19|Movie_19|Action|  2018-12-31|9.529916218E7|\n",
            "|      20|Movie_20|Sci-Fi|  2019-12-31|7.569915467E7|\n",
            "+--------+--------+------+------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.sql(\"\"\"\n",
        "SELECT movies.genre, COUNT(*) AS number\n",
        "FROM movies\n",
        "GROUP BY movies.genre\n",
        "ORDER BY number DESC\n",
        "LIMIT 5;\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "Wju6j2qGyu5O"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBb6j9Jmz0FD",
        "outputId": "33b06c65-cc7c-4a01-d218-034d3da19f97"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+\n",
            "| genre|number|\n",
            "+------+------+\n",
            "| Drama|     6|\n",
            "|Action|     6|\n",
            "|Comedy|     4|\n",
            "|Horror|     2|\n",
            "|Sci-Fi|     2|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите актера с наибольшим количеством фильмов."
      ],
      "metadata": {
        "id": "grCGzPWh_wQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_2 = spark.sql(\"\"\"\n",
        "SELECT a.name, COUNT(ma.movie_id) AS film_count\n",
        "FROM actors a\n",
        "JOIN movie_actors ma ON a.actor_id = ma.actor_id\n",
        "GROUP BY a.actor_id, a.name\n",
        "ORDER BY film_count DESC\n",
        "LIMIT 1;\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "SR-1Fyo5_ufl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqfIJaMFA1Zy",
        "outputId": "000c3218-516c-42d2-b8db-78eca2656836"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+\n",
            "|    name|film_count|\n",
            "+--------+----------+\n",
            "|Actor_17|         5|\n",
            "+--------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подсчитайте средний бюджет фильмов по жанрам."
      ],
      "metadata": {
        "id": "Ct7Y29ejBFZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_3 = spark.sql(\"\"\"\n",
        "SELECT movies.genre, AVG(movies.budget)\n",
        "FROM movies\n",
        "GROUP BY movies.genre\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "7GouL8D0BCY6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_3.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKVeHlJvBZ9B",
        "outputId": "e1c42164-654c-41a7-e22d-b993530a8f82"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------+\n",
            "| genre|         avg(budget)|\n",
            "+------+--------------------+\n",
            "| Drama| 6.076021856166667E7|\n",
            "|Horror|      8.7281876775E7|\n",
            "|Comedy|     5.20709662225E7|\n",
            "|Action|2.7492742561666667E7|\n",
            "|Sci-Fi|       7.809715175E7|\n",
            "+------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Найдите фильмы, в которых снялось более одного актера из одной страны."
      ],
      "metadata": {
        "id": "nn0sNZnUBsQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_4 = spark.sql(\"\"\"\n",
        "SELECT m.title, a.country, COUNT(*) AS actor_count\n",
        "FROM movies m\n",
        "JOIN movie_actors ma ON m.movie_id = ma.movie_id\n",
        "JOIN actors a ON ma.actor_id = a.actor_id\n",
        "GROUP BY m.title, a.country\n",
        "HAVING COUNT(*) > 1;\n",
        "\"\"\")\n",
        "\n",
        "df_4.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76FS_CkLBuat",
        "outputId": "3fcef664-b96b-473c-fec4-384a4a6e9d9d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-----------+\n",
            "|   title|  country|actor_count|\n",
            "+--------+---------+-----------+\n",
            "| Movie_7|    India|          2|\n",
            "| Movie_3|      USA|          2|\n",
            "|Movie_10|       UK|          2|\n",
            "|Movie_15|    India|          2|\n",
            "|Movie_18|Australia|          2|\n",
            "| Movie_1|    India|          3|\n",
            "| Movie_2|      USA|          2|\n",
            "| Movie_7|      USA|          2|\n",
            "|Movie_10|      USA|          2|\n",
            "+--------+---------+-----------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}